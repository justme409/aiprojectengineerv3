from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
import os
import logging

logger = logging.getLogger(__name__)

# LLM Configuration following V9 patterns
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL_2", "gemini-2.5-pro"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)

class PlanItem(BaseModel):
    """Defines an item in the plan adjacency list."""
    thinking: Optional[str] = Field(None, description="Internal reasoning placeholder; MUST be null.")
    id: str = Field(..., description="Simple identifier for this item.")
    parentId: Optional[str] = Field(None, description="Parent simple ID (null for top-level sections).")
    item_no: str = Field(..., description="Hierarchical number (e.g., '1.0', '1.1').")
    title: str = Field(description="Section or block title.")
    content_type: str = Field(description="Type of content: 'section', 'paragraph', 'list', 'table', 'checklist'.")
    content: str = Field(description="The actual content of this plan item.")
    label: Optional[str] = Field(None, description="Reference label (e.g., 'Ref: SPEC 03300 ยง3.2').")
    url: Optional[str] = Field(None, description="Reference URL if applicable.")

class PlanResponse(BaseModel):
    """Response model for plan generation"""
    items: List[PlanItem]

class PlanGenerationState(BaseModel):
    """State following V9 TypedDict patterns"""
    project_id: str
    txt_project_documents: List[Dict[str, Any]] = []
    plan_type: str = "comprehensive"  # pqp, emp, ohsmp, tmp, or comprehensive
    generated_plans: List[Dict[str, Any]] = []
    error: Optional[str] = None

class InputState(BaseModel):
    """Input state for plan generation"""
    project_id: str
    txt_project_documents: List[Dict[str, Any]] = []
    plan_type: str = "comprehensive"

class OutputState(BaseModel):
    """Output state for plan generation"""
    generated_plans: List[Dict[str, Any]] = []
    error: Optional[str] = None

def generate_comprehensive_plans(state: PlanGenerationState) -> PlanGenerationState:
    """Generate comprehensive management plans using LLM following V9 patterns - NO MOCK DATA"""
    docs = state.txt_project_documents or []
    combined_content = "\n\n".join([
        f"Document: {d.get('file_name','Unknown')} (ID: {d.get('id','')})\n{d.get('content','')}" for d in docs
    ])

    # Fail fast: require non-empty documents and content
    if not docs or not combined_content.strip():
        raise ValueError("Plan generation requires extracted document content; none available")

    # Define plan types to generate
    plan_types = [
        ("pqp", "Quality Management Plan"),
        ("emp", "Environmental Management Plan"),
        ("ohsmp", "Occupational Health and Safety Management Plan"),
        ("tmp", "Traffic Management Plan")
    ]

    generated_plans = []

    for plan_key, plan_name in plan_types:
        try:
            prompt = f"""You are a senior civil engineer producing FINAL, IMPLEMENTABLE management plans for immediate use on the project.

Create a comprehensive {plan_name} based on the project documents provided. The plan must be tailored to the specific project requirements and follow industry best practices.

**VERY IMPORTANT REQUIREMENTS:**
- Be exhaustive and highly detailed across ALL sections
- Target 2-4x the content of a typical plan
- Prefer specificity grounded in PROJECT DOCUMENTS
- Where information is absent, provide best-practice defaults marked as 'Assumption'
- Include: purpose, scope, definitions, roles & responsibilities, procedures, resources, standards, acceptance criteria, inspections, records
- Provide matrices/tables where suitable: RACI, risk registers, checklists, KPIs
- Structure deeply with multiple levels of sections and detailed content blocks
- Use adjacency list format with parentId relationships

**PROJECT DOCUMENTS:**
{combined_content}

**PLAN TYPE:** {plan_name}

Generate a comprehensive {plan_name} with the following structure:
1. **Executive Summary** - Overview and key objectives
2. **Scope and Objectives** - What the plan covers
3. **Roles and Responsibilities** - Who does what
4. **Procedures and Processes** - Step-by-step methods
5. **Risk Management** - Identification and controls
6. **Monitoring and Reporting** - How progress is tracked
7. **Training and Competency** - Required skills and training
8. **Resources and Equipment** - What's needed
9. **Documentation and Records** - What must be kept
10. **References** - Standards and documents referenced

For each section, create:
- Section headers with hierarchical numbering (1.0, 1.1, 2.0, etc.)
- Detailed content blocks with procedures, checklists, and requirements
- References to project documents where applicable
- Specific acceptance criteria and quality requirements

Output the complete plan as a structured JSON with an "items" array containing all plan elements in adjacency list format.
"""

            structured_llm = llm.with_structured_output(PlanResponse, method="json_mode")
            response: PlanResponse = structured_llm.invoke(prompt)

            if not response or not response.items:
                logger.warning(f"No structured items returned for {plan_name}")
                continue

            # Store LLM outputs in content per knowledge graph
            llm_outputs = {
                "plan_generation": {
                    "extraction": {
                        "model": os.getenv("GEMINI_MODEL_2", "gemini-2.5-pro"),
                        "timestamp": "2025-01-01T00:00:00.000Z",
                        "confidence": 0.85,
                        "method": "structured_output"
                    },
                    "summary": {
                        "short": f"{plan_name} generated",
                        "executive": f"Comprehensive {plan_name} created from {len(docs)} documents",
                        "technical": f"LLM-based plan generation with detailed procedures, checklists, and compliance requirements"
                    },
                    "structure": {
                        "plan_type": plan_key,
                        "total_items": len(response.items),
                        "sections": len([i for i in response.items if i.content_type == "section"]),
                        "content_blocks": len([i for i in response.items if i.content_type != "section"])
                    }
                }
            }

            generated_plans.append({
                "plan_type": plan_key,
                "plan_name": plan_name,
                "plan_items": [item.model_dump() for item in response.items],
                "llm_outputs": llm_outputs,
                "created_at": "2025-01-01T00:00:00.000Z"
            })

        except Exception as e:
            logger.error(f"Failed to generate {plan_name}: {e}")
            continue

    return PlanGenerationState(
        project_id=state.project_id,
        txt_project_documents=state.txt_project_documents,
        plan_type=state.plan_type,
        generated_plans=generated_plans,
        error=state.error
    )

# Graph definition following V9 patterns
def create_plan_generation_graph():
    """Create the plan generation graph with persistence"""
    from langgraph.graph import StateGraph, START, END
    from langgraph.checkpoint.sqlite import SqliteSaver

    graph = StateGraph(PlanGenerationState, input=InputState, output=OutputState)

    # Add nodes following V9 patterns
    graph.add_node("generate_plans", generate_comprehensive_plans)
    graph.add_node("create_asset_spec", lambda state: {
        "asset_specs": [create_plan_asset_spec(state)]
    })

    # Define flow following V9 patterns
    graph.set_entry_point("generate_plans")
    graph.add_edge("generate_plans", "create_asset_spec")
    graph.add_edge("create_asset_spec", END)

    return graph.compile(checkpointer=True)

def create_plan_asset_spec(state: PlanGenerationState) -> Dict[str, Any]:
    """Create asset write specification for plans following knowledge graph"""
    if not state.generated_plans:
        return {}

    # Combine all plans into a single comprehensive asset
    plans_content = {
        "plans": state.generated_plans,
        "summary": {
            "total_plans": len(state.generated_plans),
            "plan_types": [plan["plan_type"] for plan in state.generated_plans],
            "total_sections": sum(len(plan["plan_items"]) for plan in state.generated_plans)
        }
    }

    spec = {
        "asset": {
            "type": "plan",
            "name": "Comprehensive Management Plans",
            "project_id": state.project_id,
            "approval_state": "not_required",
            "classification": "internal",
            "content": plans_content,
            "metadata": {
                "plan_type": "comprehensive_management",
                "category": "management",
                "tags": ["plans", "management", "quality", "environmental", "safety", "traffic"],
                "llm_outputs": {
                    "plan_generation": {
                        "model": os.getenv("GEMINI_MODEL_2", "gemini-2.5-pro"),
                        "timestamp": "2025-01-01T00:00:00.000Z",
                        "total_plans": len(state.generated_plans)
                    }
                }
            },
            "status": "draft"
        },
        "idempotency_key": f"plans:{state.project_id}",
        "edges": []
    }

    return spec

# Description: V10 Plan generation converted from V9 patterns.
# Uses LLM with structured output instead of mock data.
# Stores results in assets.metadata.llm_outputs per knowledge graph.
# NO MOCK DATA - Real LLM calls with comprehensive management plans.


